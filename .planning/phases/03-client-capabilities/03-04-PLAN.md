---
phase: 03-client-capabilities
plan: 04
type: execute
wave: 2
depends_on: [03-03]
files_modified:
  - src/mcpp/client/sampling.h
  - src/mcpp/client/sampling.cpp
autonomous: true

must_haves:
  truths:
    - "CreateMessageRequest includes tools and tool_choice parameters"
    - "SamplingHandler can return tool_use content in result"
    - "Tool loop executes when stop_reason is 'toolUse'"
    - "Client calls MCP server tools during tool loop"
    - "Tool results are added to messages for next iteration"
    - "Loop terminates after max_iterations or when no tool use"
    - "Configurable timeout prevents infinite loops"
  artifacts:
    - path: "src/mcpp/client/sampling.h"
      provides: "Tool use support in sampling (ToolUseContent, ToolResultContent, ToolLoopConfig)"
      contains: "ToolUseContent"
    - path: "src/mcpp/client/sampling.cpp"
      provides: "Tool loop implementation in SamplingClient"
      contains: "execute_tool_loop"
  key_links:
    - from: "src/mcpp/client/sampling.cpp"
      to: "McpClient::send_request"
      via: "Call tools during tool loop"
      pattern: "tools/call"
    - from: "src/mcpp/client/sampling.cpp"
      to: "CreateMessageResult.stop_reason"
      via: "Check for toolUse"
      pattern: "stop_reason.*toolUse"
---

<objective>
Implement tool use support in sampling for agentic behaviors with configurable tool loops.

Purpose: Enable MCP servers to orchestrate complex workflows using tools. When server includes tools in sampling/createMessage request, LLM may return tool_use content. Client must call tools via MCP server, collect results, and send back for next iteration. This is CLNT-03 (agentic tool loops).

Output: ToolUseContent/ToolResultContent types, ToolLoopConfig for iteration control, tool loop executor in SamplingClient, integration with McpClient for tool calls.

Context: CLNT-03 requirement (Sampling with tool use). Depends on 03-03 (basic sampling). Tool loops are the foundation of agentic AI - LLM decides to call tools, client executes, results fed back. This requires careful iteration limits and timeout handling to prevent infinite loops.
</objective>

<execution_context>
@/home/kotdath/.claude/get-shit-done/workflows/execute-plan.md
@/home/kotdath/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-client-capabilities/03-RESEARCH.md

@src/mcpp/client/sampling.h
@src/mcpp/client/sampling.cpp
@src/mcpp/client.h
</context>

<tasks>

<task type="auto">
  <name>Extend sampling types for tool use</name>
  <files>src/mcpp/client/sampling.h</files>
  <action>
    Update src/mcpp/client/sampling.h to add tool use support:

    1. Extend ContentBlock variant to include tool types:
       ```cpp
       struct ToolUseContent {
           std::string type = "tool_use";
           std::string id;  // Unique ID for this tool use
           std::string name;  // Tool name
           nlohmann::json arguments;  // Tool arguments
       };

       struct ToolResultContent {
           std::string type = "tool_result";
           std::string tool_use_id;  // References ToolUseContent.id
           std::optional<std::string> content;  // Text result
           std::optional<bool> is_error;  // True if tool call failed
       };

       using ContentBlock = std::variant<TextContent, ToolUseContent, ToolResultContent>;
       ```

    2. Add to CreateMessageRequest:
       - std::optional<std::vector<Tool>> tools;  // Tools available to LLM
       - std::optional<ToolChoice> tool_choice;  // "auto", "required", "none", or specific tool

    3. Add ToolChoice variant:
       ```cpp
       struct ToolChoiceAuto { std::string type = "auto"; };
       struct ToolChoiceRequired { std::string type = "required"; };
       struct ToolChoiceNone { std::string type = "none"; };
       struct ToolChoiceTool {
           std::string type = "tool";
           std::string name;  // Specific tool to use
       };
       using ToolChoice = std::variant<ToolChoiceAuto, ToolChoiceRequired, ToolChoiceNone, ToolChoiceTool>;
       ```

    4. Add Tool type (minimal - server provides full schema):
       ```cpp
       struct Tool {
           std::string name;
           nlohmann::json input_schema;  // JSON Schema for arguments
       };
       ```

    5. Add ToolLoopConfig:
       ```cpp
       struct ToolLoopConfig {
           size_t max_iterations = 10;  // Maximum tool iterations
           std::chrono::milliseconds timeout = std::chrono::milliseconds(300000);  // 5 minutes
       };
       ```

    6. Update SamplingClient to include tool loop:
       - Add: void set_tool_loop_config(ToolLoopConfig config)
       - Add: std::function<JsonValue(std::string_view, const JsonValue&)> tool_caller_;  // For calling tools
       - Add: void set_tool_caller(std::function<JsonValue(std::string_view, const JsonValue&)> caller)

    7. Add helper: ContentBlock content_block_from_json(const nlohmann::json& j)

    These additions enable the tool loop: LLM returns tool_use, client extracts tool name/args, calls via MCP server, gets result, feeds back.
  </action>
  <verify>grep "struct ToolUseContent" src/mcpp/client/sampling.h returns the struct</verify>
  <done>sampling.h extended with ToolUseContent, ToolResultContent, ToolChoice, Tool, and ToolLoopConfig</done>
</task>

<task type="auto">
  <name>Implement tool loop executor</name>
  <files>src/mcpp/client/sampling.cpp</files>
  <action>
    Update src/mcpp/client/sampling.cpp with tool loop implementation:

    1. Update CreateMessageRequest::from_json:
       - Parse tools array if present: std::vector<Tool> tools
       - Parse tool_choice if present (variant type)
       - Include both in returned request

    2. Implement content_block_from_json:
       - Check type field
       - Return appropriate ContentBlock variant (Text, ToolUse, ToolResult)
       - Return nullopt if unknown type

    3. Implement tool loop function:
       ```cpp
       CreateMessageResult execute_tool_loop(
           const CreateMessageRequest& request,
           std::function<CreateMessageResult(const CreateMessageRequest&)> llm_call
       ) {
           std::vector<SamplingMessage> messages = request.messages;
           size_t iterations = 0;
           auto start_time = std::chrono::steady_clock::now();

           while (iterations < config_.max_iterations) {
               // Check timeout
               auto elapsed = std::chrono::steady_clock::now() - start_time;
               if (elapsed > config_.timeout) {
                   throw std::runtime_error("Tool loop timeout");
               }

               // Call LLM
               CreateMessageResult result = llm_call(request_with_current_messages);

               // Check if result contains tool use
               if (result.stop_reason == "toolUse" || contains_tool_use(result.content)) {
                   // Extract tool use(s) from content
                   auto tool_uses = extract_tool_uses(result.content);

                   // For each tool use, call the tool
                   for (const auto& tool_use : tool_uses) {
                       if (!tool_caller_) {
                           throw std::runtime_error("No tool caller registered");
                       }

                       // Call tool via tool_caller_ (sends tools/call to server)
                       JsonValue call_params = {
                           {"name", tool_use.name},
                           {"arguments", tool_use.arguments}
                       };
                       JsonValue tool_result_json = tool_caller_("tools/call", call_params);

                       // Parse tool result
                       ToolResultContent tool_result;
                       tool_result.tool_use_id = tool_use.id;
                       // Extract content from result...
                       tool_result.content = extract_content_from_result(tool_result_json);

                       // Add tool result to messages
                       messages.push_back({.role = "assistant", .content = result.content});  // Assistant's tool use
                       messages.push_back({.role = "user", .content = tool_result});  // User's tool result
                   }

                   iterations++;
               } else {
                   // No tool use, return final result
                   return result;
               }
           }

           // Max iterations reached
           throw std::runtime_error("Tool loop max iterations exceeded");
       }
       ```

    4. Update SamplingClient::handle_create_message:
       - If request has tools and tool_caller_ is set, use execute_tool_loop
       - Otherwise, simple single call to handler

    5. Implement set_tool_loop_config and set_tool_caller

    The tool loop enables agentic behavior: LLM calls tools, results feed back, LLM continues until done or limit reached.
  </action>
  <verify>grep -c "execute_tool_loop" src/mcpp/client/sampling.cpp returns 1 or more</verify>
  <done>sampling.cpp implements tool loop with iteration limits, timeout, and tool calling via tool_caller_</done>
</task>

<task type="auto">
  <name>Connect tool loop to McpClient</name>
  <files>src/mcpp/client.h src/mcpp/client.cpp</files>
  <action>
    Update McpClient to enable tool calling for SamplingClient:

    1. Add public method to client.h:
       - void enable_tool_use_for_sampling(bool enable = true)

    2. In client.cpp, implement enable_tool_use_for_sampling:
       - If enable, set tool_caller_ on sampling_client_:
         sampling_client_.set_tool_caller([this](std::string_view method, const JsonValue& params) -> JsonValue {
             // This needs to be synchronous for the tool loop
             // Use std::promise/future or blocking wait
             // For now, simplified: send request and wait for response

             // Generate request ID
             auto id = request_tracker_.next_id();

             // Create promise/future for blocking wait
             auto promise = std::make_shared<std::promise<JsonValue>>();
             auto future = promise->get_future();

             // Register pending request
             request_tracker_.register_pending(id,
                 [promise](const JsonValue& result) {
                     promise->set_value(result);
                 },
                 [promise](const JsonRpcError& error) {
                     promise->set_value(nlohmann::json{
                         {"error", true},
                         {"code", error.code},
                         {"message", error.message}
                     });
                 }
             );

             // Build and send request
             JsonRpcRequest req;
             req.id = id;
             req.method = std::string(method);
             req.params = params;
             transport_->send(req.to_string());

             // Wait for response (with timeout)
             // Note: This blocks the event loop - in production would need async approach
             // For MVP, this is acceptable limitation
             future.wait();

             return future.get();
         });

       - If !enable, clear tool_caller_ (set to nullptr)

    3. Add tool_loop_config accessor:
       - client::ToolLoopConfig& get_tool_loop_config() { return sampling_client_.get_tool_loop_config(); }

    This enables the SamplingClient to call tools on the MCP server during tool loops.
  </action>
  <verify>grep "enable_tool_use_for_sampling" src/mcpp/client.h returns the method</verify>
  <done>McpClient provides enable_tool_use_for_sampling and sets up tool_caller for synchronous tool calls</done>
</task>

</tasks>

<verification>
After all tasks complete, verify:

1. **Tool use content types**: ToolUseContent and ToolResultContent defined
2. **ToolChoice variant**: Supports auto, required, none, and specific tool
3. **Tool loop config**: max_iterations and timeout configurable
4. **Tool loop executor**: execute_tool_loop handles LLM response with tool use
5. **Tool calling**: set_tool_caller allows calling tools via MCP server
6. **Client integration**: enable_tool_use_for_sampling sets up tool_caller

Manual verification (if needed):
- Create request with tools, execute tool loop - tools are called
- Set max_iterations to 1, loop terminates after one tool call
- Set timeout to short duration, loop times out appropriately
- Stop reason "toolUse" triggers tool loop, "endTurn" exits loop
</verification>

<success_criteria>
1. ToolUseContent with id, name, arguments
2. ToolResultContent with tool_use_id, content, is_error
3. ToolChoice variant (auto, required, none, tool)
4. ToolLoopConfig with max_iterations and timeout
5. execute_tool_loop handles tool use responses
6. McpClient enables tool use via enable_tool_use_for_sampling
</success_criteria>

<output>
After completion, create `.planning/phases/03-client-capabilities/03-04-SUMMARY.md` with:
- Frontmatter: phase, plan, wave, depends_on: ["03-03"], affects: ["03-client-capabilities"], subsystem: "client", tech-stack-added: [], patterns-established: ["agentic tool loops", "variant-based content types"], key-files: ["sampling.h", "sampling.cpp"]
- Summary of tool use implementation
- Tool loop algorithm and safety controls
- Integration with McpClient for tool calling
- Any deviations from plan
- Next: Elicitation support (03-05)
</output>
